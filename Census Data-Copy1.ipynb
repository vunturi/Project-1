{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'zip.csv' does not exist: b'zip.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c032d36919cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#read in zip.csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mzip_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"zip.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m#clear any null values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mzip_pd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'zip.csv' does not exist: b'zip.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from census import Census\n",
    "import gmaps\n",
    "from uszipcode import SearchEngine, SimpleZipcode, Zipcode\n",
    "\n",
    "#read in zip.csv\n",
    "zip_pd = pd.read_csv(\"zip.csv\")\n",
    "#clear any null values\n",
    "zip_pd.dropna(inplace= True)\n",
    "#filter df to only include standard zip codes(exclude unique and p.o. boxes)\n",
    "std_pd= zip_pd.loc[zip_pd.Type==\"Standard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to only include zip codes in Dallas County\n",
    "county_zip_pd= std_pd.loc[(std_pd[\"County\"]== \"Dallas\") | (std_pd[\"County\"]== \"Harris\")]\n",
    "#extract all zip codes in Dallas County to a list\n",
    "county_zips = county_zip_pd[\"Zip Code\"].tolist()\n",
    "#create lists for lat and long per zip code\n",
    "lat=[]\n",
    "long=[]\n",
    "for z in county_zips:\n",
    "    search= SearchEngine()\n",
    "    zipcode= search.by_zipcode(z)\n",
    "    latitude= zipcode.lat\n",
    "    lat.append(latitude)\n",
    "    longitude= zipcode.lng\n",
    "    long.append(longitude)\n",
    "#create dictionary\n",
    "county_zips_dict={\"Zip_Codes\": county_zips,\"Lat\":lat, \"Lon\":long}\n",
    "#convert list to DF in order to merge later with Census data\n",
    "county_zip_df= pd.DataFrame(county_zips_dict)\n",
    "county_zip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey= \"f342c203f985f826ddbfc242fce4a634199dbcd5\"\n",
    "#from config import api_key\n",
    "c = Census(apikey,year=2017)\n",
    "# run api call for general tableid/variables\n",
    "census_data = c.acs5.get((\"NAME\", \"B19013_001E\", \"B01003_001E\", \"B01002_001E\",\n",
    "                          \"B19301_001E\",\n",
    "                          \"B17001_002E\"), {'for': 'zip code tabulation area:*'})\n",
    "\n",
    "# Convert to DataFrame\n",
    "census_pd = pd.DataFrame(census_data)\n",
    "\n",
    "# Column Reordering\n",
    "census_pd = census_pd.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                      \"B01002_001E\": \"Median Age\",\n",
    "                                      \"B19013_001E\": \"Household Income\",\n",
    "                                      \"B19301_001E\": \"Per Capita Income\",\n",
    "                                      \"B17001_002E\": \"Poverty Count\",\n",
    "                                      \"NAME\": \"Name\", \"zip code tabulation area\": \"Zip_Codes\"})\n",
    "#convert Zip Codes to numeric, in order to merge later\n",
    "census_pd.Zip_Codes= pd.to_numeric(census_pd.Zip_Codes)\n",
    "census_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge Zip DF with Census DF\n",
    "zip_census_merge= pd.merge(county_zip_df,census_pd, on=\"Zip_Codes\")\n",
    "zip_census_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#census data table info: https://www.census.gov/programs-surveys/acs/guidance/which-data-tool/table-ids-explained.html\n",
    "# ACS Census Table search https://factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t\n",
    "# variable list https://api.census.gov/data/2017/acs/acs5/variables.html\n",
    "#census data documentation https://jtleider.github.io/censusdata/\n",
    "# census table id variables explained https://www.census.gov/programs-surveys/acs/guidance/which-data-tool/table-ids-explained.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pull population data for 15-44 year olds, the demographic most likely to order delivery####\n",
    "#from config import api_key\n",
    "c = Census(apikey,year=2017)\n",
    "#get male population data for 15-44yr olds\n",
    "male_age_data = c.acs5.get((\"NAME\", \"B01001_006E\",\"B01001_007E\",\"B01001_008E\",\"B01001_009E\",\"B01001_010E\",\"B01001_011E\",\n",
    "                      \"B01001_012E\",\"B01001_013E\",\"B01001_014E\"), {'for': 'zip code tabulation area:*'})\n",
    "#get female population data for 15-44yr olds\n",
    "female_age_data = c.acs5.get((\"NAME\", \"B01001_030E\",\"B01001_031E\",\"B01001_032E\",\"B01001_033E\",\"B01001_034E\",\"B01001_035E\",\n",
    "                      \"B01001_036E\",\"B01001_037E\",\"B01001_038E\"), {'for': 'zip code tabulation area:*'})\n",
    "# Convert to DataFrame\n",
    "male_pd = pd.DataFrame(male_age_data)\n",
    "male_pd= male_pd.rename(columns={\"zip code tabulation area\": \"Zip_Codes\"})\n",
    "female_pd= pd.DataFrame(female_age_data)\n",
    "female_pd= female_pd.rename(columns={\"zip code tabulation area\": \"Zip_Codes\"})\n",
    "\n",
    "# Total population by gender\n",
    "male_pd[\"Total_Male\"]= male_pd.B01001_006E + male_pd.B01001_007E + male_pd.B01001_008E + male_pd.B01001_009E \\\n",
    "    + male_pd.B01001_010E + male_pd.B01001_011E + male_pd.B01001_012E + male_pd.B01001_013E + male_pd.B01001_014E\n",
    "female_pd[\"Total_Female\"]= female_pd.B01001_030E + female_pd.B01001_031E + female_pd.B01001_032E + female_pd.B01001_033E \\\n",
    "    + female_pd.B01001_034E + female_pd.B01001_035E + female_pd.B01001_036E + female_pd.B01001_037E + female_pd.B01001_038E\n",
    "#rename zip code tabulation area to Zip_Codes to align with other dataframes\n",
    "#male_pd= male_pd.rename(columns={\"zip code tabulation area\": \"Zip_Codes\"})\n",
    "#female_pd= female_pd.rename(columns={\"zip code tabulation area\": \"Zip_Codes\"})\n",
    "#merge male and female df's\n",
    "gender_merge= pd.merge(male_pd,female_pd, on=\"Zip_Codes\")\n",
    "#calculate new column for total 15-44 yr olds\n",
    "gender_merge.loc[:,\"Total\"]=gender_merge.Total_Male + gender_merge.Total_Female\n",
    "# filter DF to include only Total and Zip Codes\n",
    "gender_df = gender_merge[[\"Total\", \"Zip_Codes\"]]\n",
    "#convert Zip_codes to numeric\n",
    "gender_df.Zip_Codes= pd.to_numeric(gender_df.Zip_Codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge gender_df with zip_census_merge\n",
    "demographic_df= pd.merge(zip_census_merge,gender_df, on=\"Zip_Codes\")\n",
    "demographic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps.configure(api_key=\"\")\n",
    "figure_layout={\n",
    "    'width': '400px',\n",
    "    'height': '400px',\n",
    "    'border': '1px solid black',\n",
    "    'padding': '1px'\n",
    "}\n",
    "locations= demographic_df[[\"Lat\",\"Lon\"]]\n",
    "total = demographic_df[\"Total\"].astype(float)\n",
    "fig= gmaps.figure(map_type=\"TERRAIN\", layout=figure_layout)\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights=total, \n",
    "                                 dissipating=False, max_intensity=10,\n",
    "                                 point_radius=1)\n",
    "fig.add_layer(heat_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
